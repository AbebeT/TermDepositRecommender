{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3b6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "# import library for preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from utilities.utlity import * \n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# import libraries for cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# import evaluation metrics\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_recall_curve, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262e93fb",
   "metadata": {},
   "source": [
    "## import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc77a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "\n",
    "dataset = pd.read_csv('data/bank-additional/bank-additional-full.csv', sep=';')\n",
    "dataset.name = 'dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ee1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2962fdb",
   "metadata": {},
   "source": [
    "# Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19715ea",
   "metadata": {},
   "source": [
    "#### Check the shape and size of the imported dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b12e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape(dataset)\n",
    "size(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa908e1",
   "metadata": {},
   "source": [
    "Our dataset has 4119 rows and 21 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88953168",
   "metadata": {},
   "source": [
    "#### Check the schema of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8079ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_info(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b2cbb1",
   "metadata": {},
   "source": [
    "#### Check the statiscical data of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c487fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf78b1",
   "metadata": {},
   "source": [
    "#### Unique values of each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfadc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_unique_values(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a87288e",
   "metadata": {},
   "source": [
    "#### Check each column and the number of rows with no value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6103501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_missing_val(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b3bf1b",
   "metadata": {},
   "source": [
    "The result shows that the dataset doesn't have missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67a108f",
   "metadata": {},
   "source": [
    "### Explore the columns that have categoriacal data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc40691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns\n",
    "categorical_data = dataset.select_dtypes(exclude='number')\n",
    "categorical_data.name = \"categorical_data\";\n",
    "categorical_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e014066",
   "metadata": {},
   "source": [
    "#### 11 out of 20 columns have non numerical data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2a5330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical columns\n",
    "numberical_data = dataset.select_dtypes(include='number')\n",
    "numberical_data.name = \"numberical_data\";\n",
    "numberical_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c832ab3c",
   "metadata": {},
   "source": [
    "#### 10 out of 20 columns have non numerical data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f009f458",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbc2c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize correlation between the columns that have numberical data dype\n",
    "sns.heatmap(dataset.corr(), annot=True, fmt='.1g', \n",
    "                 vmin=-1, vmax=1, center= 0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beeaaec",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215feb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copying the dataset to a new df to handle outliers\n",
    "dataset_new = dataset.copy(deep=True)\n",
    "dataset_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432dddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using boxplot to identify outliers\n",
    "for col in numberical_data:\n",
    "    ax = sns.boxplot(numberical_data[col])\n",
    "    # save(f\"{col}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f2079",
   "metadata": {},
   "source": [
    "Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the value count in the target variable 'y'\n",
    "print(\"Value count in y\\n-----------------\\n\",dataset.y.value_counts())\n",
    "\n",
    "# percentage of yes and no\n",
    "print(\"\\nPercentage of value count in y\\n------------------------------\\n\",\n",
    "      dataset.y.value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acb3be9",
   "metadata": {},
   "source": [
    "### Replacing outlier datapoints with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# treating outliers\n",
    "count = 1\n",
    "for col in numberical_data:\n",
    "    Q1 = numberical_data[col].quantile(0.25)\n",
    "    Q3 = numberical_data[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    print(f'column {count}: {numberical_data[col].name}\\n------------------------')\n",
    "    print('1st quantile => ',Q1)\n",
    "    print('3rd quantile => ',Q3)\n",
    "    print('IQR =>',IQR)\n",
    "\n",
    "    fence_low  = Q1-(1.5*IQR)\n",
    "    print('fence_low => ' + str(fence_low))\n",
    "\n",
    "    fence_high = Q3+(1.5*IQR)\n",
    "    print('fence_high => ' + str(fence_high))\n",
    "    print(\"\\n------------------------\")\n",
    "    \n",
    "    count = count + 1\n",
    "    \n",
    "    #replacing outliers with nan\n",
    "    dataset_new[col][((dataset_new[col] < fence_low) |(dataset_new[col] > fence_high))] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cbf710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the columns which outliers were replace with nan\n",
    "print(dataset_new.select_dtypes(include='number').isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b5eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace_outliers_with_nan(numberical_data, dataset_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc18a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_column_with_nan_values(dataset_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c45fa1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with the nan values\n",
    "\n",
    "# mode\n",
    "columns_mode = ['age', 'pdays']\n",
    "for col in columns_mode:\n",
    "    dataset_new[col].fillna(dataset_new[col].mode()[0], inplace=True)\n",
    "    \n",
    "# median\n",
    "columns_median = ['duration', 'campaign', 'previous', 'cons.conf.idx']\n",
    "for col in columns_median:\n",
    "    dataset_new[col].fillna(dataset_new[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619eb725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if outliers has been removed\n",
    "for col in dataset_new.select_dtypes(include='number'):\n",
    "    ax = sns.boxplot(dataset_new.select_dtypes(include='number')[col])\n",
    "    # save(f\"{col}2\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b9951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_to_csv(dataset_new, 'bank-addition-full-without-outliers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c51bd8",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e450e670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset without outliers\n",
    "dataset_new = pd.read_csv('bank-addition-full-without-outliers.csv')\n",
    "dataset_new.name = 'New dataset'\n",
    "print(\"New Dataset\\n-------------------------\")\n",
    "print(dataset_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5bec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing - Using the new dataset i.e. data without outliers\n",
    "# replacing basic.4y, basic.6y, basic.9y as basic\n",
    "dataset_new['education'] = dataset_new['education'].replace(['basic.4y', 'basic.6y', 'basic.9y'], 'basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf921657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining output variable for classification\n",
    "dataset_new['subscribed'] = (dataset_new.y == 'yes').astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b6678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical columns\n",
    "encoded_data = encode(dataset_new)\n",
    "print(\"Encoded Data\\n-------------------------\")\n",
    "print(encoded_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c91f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed data\n",
    "preprocessed_data = preprocessed(dataset_new)\n",
    "print(\"Preprocessed Data\\n-------------------------\")\n",
    "print(preprocessed_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3491952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale numerical columns\n",
    "rescaled_data = rescale(preprocessed_data)\n",
    "print(\"Rescaled Data\\n-------------------------\")\n",
    "print(rescaled_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf269a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and target variables\n",
    "X, y = split_input_output_variables(rescaled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b9e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data\n",
    "X_train,X_test,y_train,y_test = split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2274d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_column_with_nan_values(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1107d92",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c000febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensionality reduction\n",
    "X_train_reduced, X_test_reduced = dimension_reduction('PCA', 20, X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0f1faa",
   "metadata": {},
   "source": [
    "### Dealing with imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d3a294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dealing with imbalanced class\n",
    "X_train_smote, y_train_smote = class_imbalance(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b9860",
   "metadata": {},
   "source": [
    "After sovling class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078e25d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_smote.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2592ae5",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9725933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy', 'roc_auc', 'f1', 'precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48028496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(model, cross_validation_method, metrics, X_train, X_test, y_train):\n",
    "    if (model == 'MLP'):\n",
    "        # creating an instance of the classifier\n",
    "        model_inst = MLPClassifier()\n",
    "        print('Multi Layer Perceptron\\n----------------------')\n",
    "        \n",
    "      # cross validation\n",
    "    if (cross_validation_method == 'KFold'):\n",
    "        print('Cross validation: KFold\\n--------------------------')\n",
    "        cv = KFold(n_splits=10, random_state=100, shuffle=True)\n",
    "    elif (cross_validation_method == 'StratifiedKFold'):\n",
    "        print('Cross validation: StratifiedKFold\\n-----------------')\n",
    "        cv = StratifiedKFold(n_splits=10, random_state=100, shuffle=True)\n",
    "    else:\n",
    "        print('Cross validation method not found!')\n",
    "        \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        cv_scores = cross_validate(model_inst, X_train, y_train, \n",
    "                                   cv=cv, scoring=metrics)   \n",
    "        # displaying evaluation metric scores\n",
    "        cv_metric = cv_scores.keys()\n",
    "        for metric in cv_metric:\n",
    "            mean_score = cv_scores[metric].mean()*100\n",
    "            print(metric+':', '%.2f%%' % mean_score)\n",
    "            print('')\n",
    "            \n",
    "    except:\n",
    "        metrics = ['accuracy', 'f1', 'precision', 'recall']\n",
    "        cv_scores = cross_validate(model_inst, X_train, y_train, \n",
    "                                   cv=cv, scoring=metrics)\n",
    "        # displaying evaluation metric scores\n",
    "        cv_metric = cv_scores.keys()\n",
    "        for metric in cv_metric:\n",
    "            mean_score = cv_scores[metric].mean()*100\n",
    "            print(metric+':', '%.2f%%' % mean_score)\n",
    "            print('')\n",
    "    return model_inst\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f8701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to make predictions\n",
    "def prediction(model, model_name, X_train, y_train, X_test, y_test):\n",
    "    model_ = model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    #Get the confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cf_matrix, annot=True, fmt='.0f')\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.savefig(f'conf_{model_name}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ab7bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Multi Layer Perceptron\n",
    "# KFold cross validation\n",
    "model_res = model('MLP', 'KFold', metrics, X_train_smote, X_test_reduced, y_train_smote)\n",
    "# StratifiedKFold cross validation\n",
    "# model_res = model('MLP', 'StratifiedKFold', metrics, X_train_smote, X_test_reduced, y_train_smote)\n",
    "# make prediction\n",
    "prediction(model_res, 'Multi Layer Perceptron', X_train_smote, y_train_smote, X_test_reduced, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362bfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
